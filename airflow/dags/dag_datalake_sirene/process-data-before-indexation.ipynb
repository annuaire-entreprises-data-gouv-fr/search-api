{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "import os, shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DATA_DIR' not in locals():\n",
    "    DATA_DIR = './data/'\n",
    "else:\n",
    "    print(DATA_DIR)\n",
    "\n",
    "if os.path.exists(DATA_DIR) and os.path.isdir(DATA_DIR):\n",
    "    shutil.rmtree(DATA_DIR)\n",
    "os.makedirs(os.path.dirname(DATA_DIR), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'OUTPUT_DATA_FOLDER' not in locals():\n",
    "    OUTPUT_DATA_FOLDER = './output/'\n",
    "else:\n",
    "    print(OUTPUT_DATA_FOLDER)\n",
    "\n",
    "if os.path.exists(OUTPUT_DATA_FOLDER) and os.path.isdir(OUTPUT_DATA_FOLDER):\n",
    "    shutil.rmtree(OUTPUT_DATA_FOLDER)\n",
    "os.makedirs(os.path.dirname(OUTPUT_DATA_FOLDER), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ELASTIC_INDEX' not in locals():\n",
    "    ELASTIC_INDEX = 'siren'\n",
    "else:\n",
    "    print(ELASTIC_INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Stock Unite Legale data\n",
    "df_unite_legale = pd.read_csv('https://files.data.gouv.fr/insee-sirene/StockUniteLegale_utf8.zip', compression='zip', dtype=str, usecols=['siren', \n",
    "       'dateCreationUniteLegale', 'sigleUniteLegale',\n",
    "       'prenom1UniteLegale','identifiantAssociationUniteLegale', 'trancheEffectifsUniteLegale', \n",
    "       'dateDernierTraitementUniteLegale', 'categorieEntreprise','etatAdministratifUniteLegale',\n",
    "       'nomUniteLegale', 'denominationUniteLegale', 'categorieJuridiqueUniteLegale',\n",
    "       'activitePrincipaleUniteLegale', 'economieSocialeSolidaireUniteLegale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df_unite_legale = df_unite_legale.rename(columns={\n",
    "    'dateCreationUniteLegale': 'date_creation_entreprise', \n",
    "    'sigleUniteLegale': 'sigle',\n",
    "    'prenom1UniteLegale': 'prenom',\n",
    "    'trancheEffectifsUniteLegale': 'tranche_effectif_salarie_entreprise',\n",
    "    'dateDernierTraitementUniteLegale': 'date_mise_a_jour',\n",
    "    'categorieEntreprise': 'categorie_entreprise',\n",
    "    'nomUniteLegale': 'nom',\n",
    "    'denominationUniteLegale': 'nom_raison_sociale',\n",
    "    'categorieJuridiqueUniteLegale': 'nature_juridique_entreprise',\n",
    "    'activitePrincipaleUniteLegale': 'activite_principale_entreprise'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def nom_complet(x):\n",
    "    if(x['nature_juridique_entreprise'] == '1000'):\n",
    "        if(x['sigle'] == x['sigle']):\n",
    "            if((x['prenom'] == x['prenom']) & (x['nom'] == x['nom'])):\n",
    "                return x['prenom'].lower()+' '+x['nom'].lower()+' ('+x['sigle'].lower()+')'\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            if((x['prenom'] == x['prenom']) & (x['nom'] == x['nom'])):\n",
    "                return x['prenom'].lower()+' '+x['nom'].lower()\n",
    "            else: \n",
    "                return None\n",
    "    else:\n",
    "        if(x['sigle'] == x['sigle']):\n",
    "            if(x['nom_raison_sociale'] == x['nom_raison_sociale']):\n",
    "                return x['nom_raison_sociale'].lower()+' ('+x['sigle'].lower()+')'\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            if(x['nom_raison_sociale'] == x['nom_raison_sociale']):\n",
    "                return x['nom_raison_sociale'].lower()\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Add nom_complet column to df_unite_legale\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_unite_legale[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnom_complet\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_unite_legale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnom_complet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py:8833\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8822\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m   8824\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m   8825\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   8826\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8831\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m   8832\u001b[0m )\n\u001b[0;32m-> 8833\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[0;32m--> 727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/apply.py:851\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/apply.py:867\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    869\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    870\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    871\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Add nom_complet column to df_unite_legale\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_unite_legale[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnom_complet\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_unite_legale\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mnom_complet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36mnom_complet\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnom_raison_sociale\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnom_raison_sociale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnom_raison_sociale\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/series.py:947\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    944\u001b[0m check_deprecated_indexers(key)\n\u001b[1;32m    945\u001b[0m key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;43mEllipsis\u001b[39;49m:\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    950\u001b[0m key_is_scalar \u001b[38;5;241m=\u001b[39m is_scalar(key)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Add nom_complet column to df_unite_legale\n",
    "df_unite_legale['nom_complet'] = df_unite_legale.apply(lambda row: nom_complet(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of departement zip codes\n",
    "all_deps = [*'-0'.join(list(str(x) for x in range(0, 10))).split('-')[1:],\n",
    "    *list(str(x) for x in range(10,20)),\n",
    "    *['2A','2B'],\n",
    "    *list(str(x) for x in range(21,95)),\n",
    "    *'-7510'.join(list(str(x) for x in range(0, 10))).split('-')[1:],\n",
    "    *'-751'.join(list(str(x) for x in range(10, 21))).split('-')[1:],\n",
    "    *['']\n",
    "    ]\n",
    "# Remove Paris zip code\n",
    "all_deps.remove('75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload geo data by departement\n",
    "for dep in all_deps:\n",
    "    url = 'https://files.data.gouv.fr/geo-sirene/last/dep/geo_siret_'+dep+'.csv.gz'\n",
    "    print(url)\n",
    "    df_dep = pd.read_csv(\n",
    "            url,\n",
    "            compression=\"gzip\",\n",
    "            dtype=str,\n",
    "            usecols=['siren', 'siret',\n",
    "           'dateCreationEtablissement', 'trancheEffectifsEtablissement',\n",
    "           'activitePrincipaleRegistreMetiersEtablissement',\n",
    "           'etablissementSiege',\n",
    "           'numeroVoieEtablissement',\n",
    "           'libelleVoieEtablissement',\n",
    "           'codePostalEtablissement', 'libelleCommuneEtablissement',\n",
    "            'codeCommuneEtablissement',\n",
    "            'dateDebut', 'etatAdministratifEtablissement', 'enseigne1Etablissement',\n",
    "           'activitePrincipaleEtablissement',\n",
    "           'geo_adresse', 'longitude', 'latitude', 'indiceRepetitionEtablissement']\n",
    "        )\n",
    "    df_dep = df_dep.rename(columns={\n",
    "            'dateCreationEtablissement': 'date_creation',\n",
    "            'trancheEffectifsEtablissement': 'tranche_effectif_salarie',\n",
    "            'activitePrincipaleRegistreMetiersEtablissement': 'activite_principale_registre_metier',\n",
    "            'etablissementSiege': 'is_siege',\n",
    "            'numeroVoieEtablissement': 'numero_voie',\n",
    "            'typeVoieEtablissement': 'type_voie',\n",
    "            'libelleVoieEtablissement': 'libelle_voie',\n",
    "            'codePostalEtablissement': 'code_postal',\n",
    "            'libelleCommuneEtablissement': 'libelle_commune',\n",
    "            'codeCommuneEtablissement': 'commune',\n",
    "            'codeCedexEtablissement': 'cedex',\n",
    "            'dateDebut_x': 'date_debut_activite', \n",
    "            'etatAdministratifEtablissement': 'etat_administratif_etablissement',\n",
    "            'enseigne1Etablissement': 'enseigne',\n",
    "            'activitePrincipaleEtablissement': 'activite_principale',\n",
    "            'indiceRepetitionEtablissement': 'indice_repetition'\n",
    "        \n",
    "        })\n",
    "    df_dep.to_csv(DATA_DIR+'geo_siret_'+dep+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get geo data file paths\n",
    "geo_files = glob.glob(DATA_DIR+\"geo_siret*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute nbre d'Ã©tablissements' per 'siren'\n",
    "df_out=pd.DataFrame()\n",
    "for geo_file in geo_files:\n",
    "    print(geo_file)\n",
    "    df_geo = pd.read_csv(geo_file,dtype=str)\n",
    "    df_geo['file'] = geo_file\n",
    "    df_geo['nombre_etablissements'] = df_geo.groupby(['siren','file'])['siret'].transform('count')\n",
    "    df_enseigne = df_geo.groupby(['siren','file'])['enseigne'].apply(set).reset_index(name='liste_enseigne').drop(columns=['file'], axis=1)\n",
    "    df_geo = df_geo.merge(df_enseigne, left_on='siren', right_on='siren')\n",
    "    df_adresse = df_geo.groupby(['siren','file'])['geo_adresse'].apply(set).reset_index(name='liste_adresse').drop(columns=['file'], axis=1)\n",
    "    df_geo = df_geo.merge(df_adresse, left_on='siren', right_on='siren')\n",
    "    df_inter = df_geo[['siren','file','nombre_etablissements', 'liste_enseigne', 'liste_adresse']]\n",
    "    df_out = pd.concat([df_out, df_inter])\n",
    "df_out = df_out.drop_duplicates(subset='siren',keep='first')\n",
    "df_out2 = df_out[['siren','nombre_etablissements']].groupby(['siren'],as_index=False).sum()\n",
    "df_out2 = df_out2.merge(df_out[['liste_enseigne', 'liste_adresse','siren']], on='siren', how='left')\n",
    "df_unite_legale = pd.merge(df_unite_legale,df_out2,on='siren',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 'nombre etablissements ouvert' per 'siren'\n",
    "df_out=pd.DataFrame()\n",
    "for geo_file in geo_files:\n",
    "    print(geo_file)\n",
    "    df_geo = pd.read_csv(geo_file,dtype=str)\n",
    "    df_geo = df_geo[df_geo['etat_administratif_etablissement'] == 'A']\n",
    "    df_geo['file'] = geo_file\n",
    "    df_geo['nombre_etablissements_ouvert'] = df_geo.groupby(['siren','file'])['siret'].transform('count')\n",
    "    df_inter = df_geo[['siren','file','nombre_etablissements_ouvert']]\n",
    "    df_out = pd.concat([df_out, df_inter])\n",
    "df_out = df_out.drop_duplicates(keep='first')\n",
    "df_out2 = df_out[['siren','nombre_etablissements_ouvert']].groupby(['siren'],as_index=False).sum()\n",
    "df_unite_legale = pd.merge(df_unite_legale,df_out2,on='siren',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge geo files with above dataframe\n",
    "for geo_file in geo_files:\n",
    "    print(geo_file)\n",
    "    df_geo = pd.read_csv(geo_file,dtype=str)\n",
    "    df_inter = pd.merge(df_geo,df_unite_legale,on='siren',how='left')\n",
    "    df_inter2 = df_inter[df_inter['is_siege'] == 'true']\n",
    "    df_inter2['concat_nom_adr_siren'] = df_inter2['nom_complet'] + ' ' + df_inter2['geo_adresse'] + ' ' + df_inter2['siren']\n",
    "    df_inter2['concat_enseigne_adresse'] = df_inter2.apply(lambda x: x.liste_enseigne.union(x.liste_adresse), axis=1)\n",
    "    df_inter.to_csv(OUTPUT_DATA_FOLDER+'siret_'+geo_file.replace(DATA_DIR+'geo_siret_',''), index=False)\n",
    "    df_inter2.to_csv(OUTPUT_DATA_FOLDER+ELASTIC_INDEX+'_'+geo_file.replace(DATA_DIR+'geo_siret_',''), index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "19ece5f74f8baf7d074e990d308e7c75b7ac8b98c7c6e76faedd0c3526d006f2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
